{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading data","metadata":{"id":"vyaky4X9c9WE"}},{"cell_type":"code","source":"!pip install --upgrade pip","metadata":{"execution":{"iopub.status.busy":"2022-06-13T15:15:30.466395Z","iopub.execute_input":"2022-06-13T15:15:30.467085Z","iopub.status.idle":"2022-06-13T15:18:11.215550Z","shell.execute_reply.started":"2022-06-13T15:15:30.466984Z","shell.execute_reply":"2022-06-13T15:18:11.214119Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install nibabel","metadata":{"id":"KKSWfuQOMvcJ","execution":{"iopub.status.busy":"2022-06-13T15:18:11.219452Z","iopub.execute_input":"2022-06-13T15:18:11.220060Z","iopub.status.idle":"2022-06-13T15:18:43.149144Z","shell.execute_reply.started":"2022-06-13T15:18:11.220021Z","shell.execute_reply":"2022-06-13T15:18:43.148135Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport glob\n\nimport nibabel as nib\nimport cv2\nimport imageio\nfrom tqdm.notebook import tqdm\nfrom ipywidgets import *\nfrom PIL import Image","metadata":{"id":"noIve5eKV7p7","execution":{"iopub.status.busy":"2022-06-13T15:18:43.152235Z","iopub.execute_input":"2022-06-13T15:18:43.152766Z","iopub.status.idle":"2022-06-13T15:18:43.728016Z","shell.execute_reply.started":"2022-06-13T15:18:43.152712Z","shell.execute_reply":"2022-06-13T15:18:43.727029Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html > /dev/null\n!pip install --upgrade kornia > /dev/null\n!pip install allennlp==1.1.0.rc4 > /dev/null","metadata":{"id":"XMmjMjckWdoF","execution":{"iopub.status.busy":"2022-06-13T15:18:43.730760Z","iopub.execute_input":"2022-06-13T15:18:43.731527Z","iopub.status.idle":"2022-06-13T15:28:49.782534Z","shell.execute_reply.started":"2022-06-13T15:18:43.731478Z","shell.execute_reply":"2022-06-13T15:28:49.781213Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade fastai > /dev/null\nimport fastai; fastai.__version__","metadata":{"id":"ADLWknjbWwpH","execution":{"iopub.status.busy":"2022-06-13T15:28:49.784257Z","iopub.execute_input":"2022-06-13T15:28:49.784637Z","iopub.status.idle":"2022-06-13T15:44:05.369176Z","shell.execute_reply.started":"2022-06-13T15:28:49.784599Z","shell.execute_reply":"2022-06-13T15:44:05.367883Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from fastai.basics import *\nfrom fastai.vision.all import *\nfrom fastai.data.transforms import *","metadata":{"id":"IwU9VcnEW0k7","execution":{"iopub.status.busy":"2022-06-13T15:44:05.371031Z","iopub.execute_input":"2022-06-13T15:44:05.371587Z","iopub.status.idle":"2022-06-13T15:44:08.039017Z","shell.execute_reply.started":"2022-06-13T15:44:05.371548Z","shell.execute_reply":"2022-06-13T15:44:08.037867Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Creat a meta file\n\nfile_list = []\nfor dirname, _, filenames in os.walk('../input/liver-tumor-segmentation'):\n  for filename in filenames:\n    #print(os.path.join(dirname, filename))\n    file_list.append((dirname, filename))\n    \nfor dirname, _, filenames in os.walk('../input/liver-tumor-segmentation-part-2'):\n    for filename in filenames:\n        file_list.append((dirname,filename))\n\ndf_files = pd.DataFrame(file_list, columns= ['dirname', 'filename'])\ndf_files.sort_values(by= ['filename'], ascending= True)","metadata":{"id":"H0SOokSiXbe3","execution":{"iopub.status.busy":"2022-06-13T15:44:08.040359Z","iopub.execute_input":"2022-06-13T15:44:08.040918Z","iopub.status.idle":"2022-06-13T15:44:08.253435Z","shell.execute_reply.started":"2022-06-13T15:44:08.040884Z","shell.execute_reply":"2022-06-13T15:44:08.252336Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Label","metadata":{}},{"cell_type":"code","source":"# Map CT scan and label\n\ndf_files[\"mask_dirname\"]= \"\"; df_files[\"mask_filename\"]= \"\"\nfor i in range(131):\n    ct = f\"volume-{i}.nii\"\n    mask = f\"segmentation-{i}.nii\"\n    \n    df_files.loc[df_files['filename'] == ct, 'mask_filename'] = mask\n    df_files.loc[df_files['filename'] == ct, 'mask_dirname'] = \"../input/liver-tumor-segmentation/segmentations\"\n\ndf_files_test= df_files[df_files.mask_filename=='']\n# drop segment rows\ndf_files = df_files[df_files.mask_filename != ''].sort_values(by=['filename']).reset_index(drop=True) \nprint(len(df_files))\nprint(df_files)","metadata":{"id":"QYqD-x9WY9ba","execution":{"iopub.status.busy":"2022-06-13T15:44:08.254932Z","iopub.execute_input":"2022-06-13T15:44:08.255270Z","iopub.status.idle":"2022-06-13T15:44:08.437028Z","shell.execute_reply.started":"2022-06-13T15:44:08.255239Z","shell.execute_reply":"2022-06-13T15:44:08.435634Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Reads .nii file and returns pixel array\nimport nibabel as nib\ndef read_nii(filepath):\n  ct_scan = nib.load(filepath)\n  array = ct_scan.get_fdata()\n  array = np.rot90(np.array(array))\n  return array","metadata":{"id":"TWEMgtrqaDoV","execution":{"iopub.status.busy":"2022-06-13T15:44:08.438700Z","iopub.execute_input":"2022-06-13T15:44:08.439419Z","iopub.status.idle":"2022-06-13T15:44:08.447158Z","shell.execute_reply.started":"2022-06-13T15:44:08.439385Z","shell.execute_reply":"2022-06-13T15:44:08.445095Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Read sample\nsample = 3\nsample_ct = read_nii(df_files.loc[sample,'dirname']+\"/\"+df_files.loc[sample,'filename'])\nsample_mask  = read_nii(df_files.loc[sample,'mask_dirname']+\"/\"+df_files.loc[sample,'mask_filename'])\nprint(sample_ct.shape)\nprint(sample_mask.shape)\nprint(df_files.loc[sample,'dirname']+\"/\"+df_files.loc[sample,'filename'])","metadata":{"id":"I-sO25XcaXHW","execution":{"iopub.status.busy":"2022-06-13T15:44:08.449054Z","iopub.execute_input":"2022-06-13T15:44:08.450279Z","iopub.status.idle":"2022-06-13T15:44:16.761822Z","shell.execute_reply.started":"2022-06-13T15:44:08.450246Z","shell.execute_reply":"2022-06-13T15:44:16.760833Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(np.amin(sample_ct), np.amax(sample_ct))\nprint(np.amin(sample_mask), np.amax(sample_mask))","metadata":{"id":"5CSXyXtnav4e","execution":{"iopub.status.busy":"2022-06-13T15:44:16.764744Z","iopub.execute_input":"2022-06-13T15:44:16.765070Z","iopub.status.idle":"2022-06-13T15:44:17.671018Z","shell.execute_reply.started":"2022-06-13T15:44:16.765040Z","shell.execute_reply":"2022-06-13T15:44:17.669857Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# Preprocess the nii file\n\ndicom_windows = types.SimpleNamespace(\n    brain = (80, 40),\n    subdural = (264, 100),\n    stroke = (8, 32),\n    brain_bone = (2800, 600),\n    brain_sofr = (375, 40),\n    lungs = (1500, -600),\n    mediastinum = (350, 50),\n    abdomen_soft = (400, 50),\n    liver = (150, 30),\n    spine_soft = (250, 50),\n    spine_bone = (1800, 400),\n    custom = (200, 60)\n)\n\n@patch\ndef windowed(self:Tensor, w, l):\n  px = self.clone()\n  px_min = l- w//2\n  px_max = 1+ w//2\n  px[px<px_min] = px_min\n  px[px>px_max] = px_max\n  return (px- px_min) / (px_max- px_min)\n","metadata":{"id":"AvJU_9Eaazne","execution":{"iopub.status.busy":"2022-06-13T15:44:47.392286Z","iopub.execute_input":"2022-06-13T15:44:47.393092Z","iopub.status.idle":"2022-06-13T15:44:47.401960Z","shell.execute_reply.started":"2022-06-13T15:44:47.393054Z","shell.execute_reply":"2022-06-13T15:44:47.400863Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"plt.imshow(tensor(sample_ct[...,50].astype(np.float32)).windowed(*dicom_windows.liver), cmap=plt.cm.bone);","metadata":{"id":"cbQ48g0tc5Kb","execution":{"iopub.status.busy":"2022-06-13T15:44:51.491195Z","iopub.execute_input":"2022-06-13T15:44:51.491582Z","iopub.status.idle":"2022-06-13T15:44:51.774548Z","shell.execute_reply.started":"2022-06-13T15:44:51.491550Z","shell.execute_reply":"2022-06-13T15:44:51.773823Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Plots and a slice with all available annotations\ndef plot_sample(array_list, color_map = 'nipy_spectral'):\n  fig = plt.figure(figsize= (18, 15))\n\n  plt.subplot(1, 4, 1)\n  plt.imshow(array_list[0], cmap= 'bone')\n  plt.title('Original Image')\n\n  plt.subplot(1, 4, 2)\n  plt.imshow(tensor(array_list[0].astype(np.float32)).windowed(*dicom_windows.liver), cmap='bone');\n  plt.title('Windowed Image')\n\n  plt.subplot(1,4,3)\n  plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n  plt.title('Mask')\n    \n  plt.subplot(1,4,4)\n  plt.imshow(array_list[0], cmap='bone')\n  plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n  plt.title('Liver & Mask')\n\n  plt.show()","metadata":{"id":"P3UE6PbtdMYj","execution":{"iopub.status.busy":"2022-06-13T15:44:53.857705Z","iopub.execute_input":"2022-06-13T15:44:53.858491Z","iopub.status.idle":"2022-06-13T15:44:53.870868Z","shell.execute_reply.started":"2022-06-13T15:44:53.858447Z","shell.execute_reply":"2022-06-13T15:44:53.869822Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"sample = 421\nsampe_slice = tensor(sample_ct[...,sample].astype(np.float32))\nplot_sample([sample_ct[...,sample], sample_mask[...,sample]])","metadata":{"id":"HxgNXvjUd9Zm","execution":{"iopub.status.busy":"2022-06-13T15:44:56.953687Z","iopub.execute_input":"2022-06-13T15:44:56.954873Z","iopub.status.idle":"2022-06-13T15:44:57.713151Z","shell.execute_reply.started":"2022-06-13T15:44:56.954820Z","shell.execute_reply":"2022-06-13T15:44:57.712003Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Cehck the mask valuse\nmask = Image.fromarray(sample_mask[...,sample].astype('uint8'), mode=\"L\")\nprint(mask.shape)\nunique, counts = np.unique(mask, return_counts=True)\nprint( np.array((unique, counts)).T)\nplt.imshow(mask , cmap = 'bone')","metadata":{"id":"zI5JJ9EmeFMI","execution":{"iopub.status.busy":"2022-06-13T15:45:00.279623Z","iopub.execute_input":"2022-06-13T15:45:00.280079Z","iopub.status.idle":"2022-06-13T15:45:00.513714Z","shell.execute_reply.started":"2022-06-13T15:45:00.280046Z","shell.execute_reply":"2022-06-13T15:45:00.512590Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Preprocessing functions\nclass TensorCTScan(TensorImageBW): _show_args = {'cmap':'bone'}\n\n@patch\ndef freqhist_bins(self:Tensor, n_bins=100):\n    \"A function to split the range of pixel values into groups, such that each group has around the same number of pixels\"\n    imsd = self.view(-1).sort()[0]\n    t = torch.cat([tensor([0.001]),\n                   torch.arange(n_bins).float()/n_bins+(1/2/n_bins),\n                   tensor([0.999])])\n    t = (len(imsd)*t).long()\n    return imsd[t].unique()\n    \n@patch\ndef hist_scaled(self:Tensor, brks=None):\n    \"Scales a tensor using `freqhist_bins` to values between 0 and 1\"\n    if self.device.type=='cuda': return self.hist_scaled_pt(brks)\n    if brks is None: brks = self.freqhist_bins()\n    ys = np.linspace(0., 1., len(brks))\n    x = self.numpy().flatten()\n    x = np.interp(x, brks.numpy(), ys)\n    return tensor(x).reshape(self.shape).clamp(0.,1.)\n    \n    \n@patch\ndef to_nchan(x:Tensor, wins, bins=None):\n    res = [x.windowed(*win) for win in wins]\n    if not isinstance(bins,int) or bins!=0: res.append(x.hist_scaled(bins).clamp(0,1))\n    dim = [0,1][x.dim()==3]\n    return TensorCTScan(torch.stack(res, dim=dim))\n\n@patch\ndef save_jpg(x:(Tensor), path, wins, bins=None, quality=90):\n    fn = Path(path).with_suffix('.jpg')\n    x = (x.to_nchan(wins, bins)*255).byte()\n    im = Image.fromarray(x.permute(1,2,0).numpy(), mode=['RGB','CMYK'][x.shape[0]==4])\n    im.save(fn, quality=quality)","metadata":{"id":"fWUzzFvaeKxc","execution":{"iopub.status.busy":"2022-06-13T15:45:03.279392Z","iopub.execute_input":"2022-06-13T15:45:03.279851Z","iopub.status.idle":"2022-06-13T15:45:03.295983Z","shell.execute_reply.started":"2022-06-13T15:45:03.279815Z","shell.execute_reply":"2022-06-13T15:45:03.294851Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Unet","metadata":{"id":"0MGET1exfP32"}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\nfrom torch import autograd\nfrom torch.autograd import Variable\nimport torch.utils.data as Data\nimport torchvision\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, models, transforms","metadata":{"id":"_ZCvPCJAelIW","execution":{"iopub.status.busy":"2022-06-13T15:45:15.041019Z","iopub.execute_input":"2022-06-13T15:45:15.041441Z","iopub.status.idle":"2022-06-13T15:45:15.048165Z","shell.execute_reply.started":"2022-06-13T15:45:15.041408Z","shell.execute_reply":"2022-06-13T15:45:15.046870Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n  def __init__(self, in_ch, out_ch):\n    super().__init__()\n    self.conv1 = nn.Conv2d(in_ch, out_ch, 3)\n    self.relu = nn.ReLU()\n    self.conv2 = nn.Conv2d(out_ch, out_ch, 3)\n  \n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.relu(x)\n    x = self.conv2(x)\n    x = self.relu(x)\n    return x","metadata":{"id":"IUIQjrPPpwR4","execution":{"iopub.status.busy":"2022-06-13T15:44:17.724360Z","iopub.execute_input":"2022-06-13T15:44:17.724696Z","iopub.status.idle":"2022-06-13T15:44:17.737676Z","shell.execute_reply.started":"2022-06-13T15:44:17.724662Z","shell.execute_reply":"2022-06-13T15:44:17.736750Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n  def __init__(self, chs= (3, 64, 128, 256, 512, 1024)):\n    super().__init__()\n    self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n    self.pool = nn.MaxPool2d(2)\n\n  def forward(self, x):\n    ftrs = []\n    for block in self.enc_blocks:\n      x = block(x)\n      ftrs.append(x)\n      x = self.pool(x)\n    return ftrs","metadata":{"id":"ZtqoQhpGq4LQ","execution":{"iopub.status.busy":"2022-06-13T15:44:17.739036Z","iopub.execute_input":"2022-06-13T15:44:17.739582Z","iopub.status.idle":"2022-06-13T15:44:17.749110Z","shell.execute_reply.started":"2022-06-13T15:44:17.739534Z","shell.execute_reply":"2022-06-13T15:44:17.747846Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n  def __init__(self, chs= (1024,  512, 256, 128, 64)):\n    super().__init__()\n    self.chs = chs\n    self.upconvs = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n    self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n\n  def forward(self, x, encoder_features):\n    for i in range(len(self.chs)-1):\n      x = self.upconvs[i](x)\n      enc_ftrs = self.crop(encoder_features[i], x)\n      x = torch.cat([x, enc_ftrs], dim= 1)\n      x = self.dec_blocks[i](x)\n    return x\n  \n  def crop(self, enc_ftrs, x):\n    _, _, H, W = x.shape\n    enc_ftrs = transforms.CenterCrop([H, W])(enc_ftrs)\n    return enc_ftrs","metadata":{"id":"A_SVuy08sJ8n","execution":{"iopub.status.busy":"2022-06-13T15:44:17.750700Z","iopub.execute_input":"2022-06-13T15:44:17.751344Z","iopub.status.idle":"2022-06-13T15:44:17.763118Z","shell.execute_reply.started":"2022-06-13T15:44:17.751297Z","shell.execute_reply":"2022-06-13T15:44:17.762275Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n  def __init__(self, enc_chs= (3, 64, 128, 256, 512, 1024),\n              dec_chs= (1024, 512, 256, 128, 64), num_class= 1,\n              retain_dim= False, out_sz= (572, 572)):\n    super().__init__()\n    self.encoder = Encoder(enc_chs)\n    self.decoder = Decoder(dec_chs)\n    self.head = nn.Conv2d(dec_chs[-1], num_class, 1)\n    self.retain_dim = retain_dim\n  \n  def forward(self, x):\n    enc_ftrs = self.encoder(x)\n    out = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n    out = self.head(out)\n    if self.retain_dim:\n      out = F.interpolate(out, out_sz)\n    return out","metadata":{"id":"BtAlpvMQvHfU","execution":{"iopub.status.busy":"2022-06-13T15:44:17.764384Z","iopub.execute_input":"2022-06-13T15:44:17.765003Z","iopub.status.idle":"2022-06-13T15:44:17.777175Z","shell.execute_reply.started":"2022-06-13T15:44:17.764956Z","shell.execute_reply":"2022-06-13T15:44:17.776372Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"unet = UNet()\nx = torch.randn(1, 3, 572, 572)\nunet(x).shape","metadata":{"id":"sPHI5tW5wQiT","outputId":"67b783cc-e78e-469b-e0eb-91ab11724467","execution":{"iopub.status.busy":"2022-06-13T15:45:26.736775Z","iopub.execute_input":"2022-06-13T15:45:26.737668Z","iopub.status.idle":"2022-06-13T15:45:30.771949Z","shell.execute_reply.started":"2022-06-13T15:45:26.737633Z","shell.execute_reply":"2022-06-13T15:45:30.770875Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Training Process","metadata":{}},{"cell_type":"markdown","source":"## Loss function\nUsing Dice loss as loss function","metadata":{}},{"cell_type":"code","source":"class DiceLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceLoss, self).__init__()\n    def forward(self, inputs, targets, smooth=1):\n        \n        #comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        \n        intersection = (inputs * targets).sum()                            \n        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n        \n        return 1 - dice","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Accuracy\nusing dice coefficient as accuracy","metadata":{}},{"cell_type":"code","source":"def dice_coeff(pred, target):\n    smooth = 1.\n    num = pred.size(0)\n    m1 = pred.view(num, -1).float()  # Flatten\n    m2 = target.view(num, -1).float()  # Flatten\n    intersection = (m1 * m2).sum().float()\n\n    return (2. * intersection + smooth) / (m1.sum() + m2.sum() + smooth)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameters","metadata":{}},{"cell_type":"code","source":"device = 'cuda'\nbatch_size = 32\nlearning_rate = 0.0001","metadata":{"id":"DTZDj-hfeC1w","execution":{"iopub.status.busy":"2022-06-04T06:50:17.391792Z","iopub.status.idle":"2022-06-04T06:50:17.392471Z","shell.execute_reply.started":"2022-06-04T06:50:17.392322Z","shell.execute_reply":"2022-06-04T06:50:17.392339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gmodel = UNet()\n#print(gmodel)\nsummary(gmodel, (3, 572, 572))\ngmodel= gmodel.to(device)\nloss_f = DcieLoss()\noptimizer = optim.AdamW(gmodel.parameters(), lr = learning_rate)","metadata":{"id":"aPjXuK0sTG19","execution":{"iopub.status.busy":"2022-06-04T06:50:17.404727Z","iopub.status.idle":"2022-06-04T06:50:17.405119Z","shell.execute_reply.started":"2022-06-04T06:50:17.404961Z","shell.execute_reply":"2022-06-04T06:50:17.404977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ntrainloss = []\nvalidloss = []\ntrainaccu = []\nvalidaccu = []","metadata":{"id":"_SvW7_ameHUZ","execution":{"iopub.status.busy":"2022-06-04T06:50:17.405966Z","iopub.status.idle":"2022-06-04T06:50:17.406416Z","shell.execute_reply.started":"2022-06-04T06:50:17.40623Z","shell.execute_reply":"2022-06-04T06:50:17.406247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''import numpy as np\nimport csv\nimport pandas as pd\nData = pd.read_csv('./model/output.csv', delimiter= ',', encoding= 'utf-8', header= None)\ndata = Data.to_numpy()\nfor i in range(0, np.size(data, axis= 1)):\n  trainloss.append(data[0][i])\n  validloss.append(data[1][i])\nfor i in range(0, np.size(data, axis= 1)):\n  trainaccu.append(data[2][i])\n  validaccu.append(data[3][i])'''\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import  tqdm\ndef train(epoch, model):\n    '''if epoch == 0:\n      checkpoint=torch.load(\"./model/checkpoint.ckpt\",map_location=device)\n      model_state, optimizer_state = checkpoint[\"model\"], checkpoint[\"optimizer\"]\n      model.load_state_dict(model_state)\n      optimizer.load_state_dict(optimizer_state)'''\n    model.train()\n    correct = 0\n    train_loss = 0\n    # for batch_idx, (data, target) in enumerate(train_loader):\n    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n        # data, target = Variable(data), Variable(target)\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = loss_f(output, target)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        correct += dice_coeff(output, target).sum().item()\n        if batch_idx % 10 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx *len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n    train_loss /= len(train_loader.dataset)\n    print('\\nTraining  set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n        train_loss, correct, len(train_loader.dataset),\n        100. * correct / len(train_loader.dataset)))\n    train_loss /= len(train_loader.dataset)\n    trainloss.append(train_loss)\n    trainaccu.append(correct / len(train_loader.dataset))","metadata":{"id":"_9KJDEnDeKmQ","execution":{"iopub.status.busy":"2022-06-04T06:50:17.407475Z","iopub.status.idle":"2022-06-04T06:50:17.407922Z","shell.execute_reply.started":"2022-06-04T06:50:17.407771Z","shell.execute_reply":"2022-06-04T06:50:17.407787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_output = []\ndef valid(model):\n    model.eval()\n    valid_loss = 0\n    correct = 0\n    loss = []\n    global valid_output\n    valid_output = []\n    for data, target in tqdm(valid_loader):\n        # data, target = Variable(data, volatile = True), Variable(target)\n        data, target = data.to(device), target.to(device)\n        output = model(data)\n        valid_output.append(output.detach().cpu().numpy())\n        # Sum up vatch loss\n        valid_loss += loss_f(output, target).data.item()\n        correct += dice_coeff(output, target).sum().item()\n    valid_loss /= len(valid_loader.dataset)\n    print('Validation  set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        valid_loss, correct, len(valid_loader.dataset),\n        100. * correct / len(valid_loader.dataset)))\n    validloss.append(valid_loss)\n    validaccu.append(correct / len(valid_loader.dataset))\n    valid_output = np.concatenate(valid_output)","metadata":{"id":"3msnYpsXeSWk","execution":{"iopub.status.busy":"2022-06-04T06:50:17.409153Z","iopub.status.idle":"2022-06-04T06:50:17.409699Z","shell.execute_reply.started":"2022-06-04T06:50:17.40953Z","shell.execute_reply":"2022-06-04T06:50:17.409547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nnum_iter= 2\nfor epoch in range(0, num_iter):\n    train(epoch, gmodel)\n    i = len(validloss)\n    valid(gmodel)\n    if validloss[i] > validloss[i-1]:\n        print(\"Validation Loss increased\")\n        break\ntorch.save({\"model\": gmodel.state_dict(), \"optimizer\": optimizer.state_dict()}, \"./model/checkpoint.ckpt\")","metadata":{"id":"Awd9EsjBfjVP","outputId":"a60abfa6-7e8d-4e74-d4ae-6124ca5f2d2a","execution":{"iopub.status.busy":"2022-06-04T06:50:17.410646Z","iopub.status.idle":"2022-06-04T06:50:17.411162Z","shell.execute_reply.started":"2022-06-04T06:50:17.411012Z","shell.execute_reply":"2022-06-04T06:50:17.411028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Result\n## Loss and Accuracy of training data and validation data","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.plot(range(0, len(trainloss)), trainloss, color = 'blue', label = 'training loss')\nplt.plot(range(0, len(validloss)), validloss, color = 'red', label = 'validation loss')\nplt.legend()\nplt.show()\n\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.plot(range(0, len(trainaccu)), trainaccu, color = 'blue', label = 'training accuracy')\nplt.plot(range(0, len(validaccu)), validaccu, color = 'red', label = 'validation accuracy')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nwith open('./output.csv','w',newline='') as f:\n  w = csv.writer(f)\n  w.writerow(trainloss)\n  w.writerow(validloss)\n  w.writerow(trainloss)\n  w.writerow(validloss)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Print an sample to compare the predicted result vs. the mask","metadata":{}},{"cell_type":"code","source":"sample = 420\nsampe_slice = tensor(sample_ct[...,sample].astype(np.float32))\nplot_sample([sample_ct[...,sample], valid_output[...,sample]])\nplot_sample([sample_ct[...,sample], sample_mask[...,sample]])","metadata":{},"execution_count":null,"outputs":[]}]}